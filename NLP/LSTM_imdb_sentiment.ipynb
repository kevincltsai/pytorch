{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevincltsai/pytorch/blob/main/imdb_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Awle1npEzPuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bb25fa-effe-44a8-af1a-559b678c0cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dDjPWq60zg6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee9c1f1-3d91-4854-8c16-65488cdd6c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/SC201L17\n"
          ]
        }
      ],
      "source": [
        "# Get to the folder we are at\n",
        "FOLDERNAME = 'Colab\\ Notebooks/SC201L17'\n",
        "%cd drive/MyDrive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y97j98Q4z7Xc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwWJ50WazslW"
      },
      "outputs": [],
      "source": [
        "# Seed for same output\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r2mgLa3M0Byv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d1d20c-9f5b-400d-d6ba-11b0bfe27d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ECfzthFg0JAx"
      },
      "outputs": [],
      "source": [
        "# Reading in our file\n",
        "raw_data = pd.read_csv('IMDBDataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_fD-STdS1YrR"
      },
      "outputs": [],
      "source": [
        "# Get data & labels\n",
        "reviews = raw_data.review\n",
        "labels = raw_data.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VOm0Ite22dDv"
      },
      "outputs": [],
      "source": [
        "# Replace 'positive' with 1; 'negative' with 0\n",
        "labels.replace({'positive':1, 'negative':0}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ok1_tvlQ2ucU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056b7660-84f8-4523-cb7d-af7681fcf04a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    One of the other reviewers has mentioned that ...\n",
              "1    A wonderful little production. <br /><br />The...\n",
              "2    I thought this was a wonderful way to spend ti...\n",
              "3    Basically there's a family where a little boy ...\n",
              "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "reviews.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zRKuY6rd3A3T"
      },
      "outputs": [],
      "source": [
        "patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n",
        "replacements = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '', '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z865Qnf56O_f"
      },
      "outputs": [],
      "source": [
        "def preprocessing(reviews, patterns, replacements):\n",
        "  lst = []\n",
        "  for i in range(len(reviews)):\n",
        "    review = reviews[i].lower()\n",
        "    for pattern, replacement in zip(patterns, replacements):\n",
        "      review = review.replace(pattern, replacement)\n",
        "\n",
        "    lst.append(review)\n",
        "\n",
        "  return lst\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CMFvQLEJ7Jm8"
      },
      "outputs": [],
      "source": [
        "reviews = preprocessing(reviews, patterns, replacements)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDOCzO37OFgT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IV8p_VRE-WWR"
      },
      "outputs": [],
      "source": [
        "num_train = 35000\n",
        "num_val = 15000\n",
        "longest_num_tokens = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8gTXoaJq7EgR"
      },
      "outputs": [],
      "source": [
        "def indexing_tokens():\n",
        "  #UNK = unknown\n",
        "  indices = {'<SOS>':0, '<EOS>':1, '<PAD>':2, '<UNK>':3}\n",
        "  counter = 4\n",
        "\n",
        "  for i in range(num_train):\n",
        "    tokens = reviews[i].split()\n",
        "    for token in tokens:\n",
        "      if token not in indices:\n",
        "        indices[token] = counter\n",
        "        counter += 1\n",
        "\n",
        "  return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2jazcczJ-zfC"
      },
      "outputs": [],
      "source": [
        "def get_data(indices, longest_line_tokens, mode='train'):\n",
        "    data = []\n",
        "    Y = []\n",
        "    if mode == 'train':\n",
        "      for i in range(num_train):\n",
        "        one_train_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "\n",
        "        #tokenizing\n",
        "        for token in tokens:\n",
        "          one_train_data.append(indices[token])\n",
        "          # max seq = longest_line_tokens\n",
        "          if len(one_train_data) == longest_line_tokens:\n",
        "            break\n",
        "        #if review len < longest_num_token\n",
        "        while len(one_train_data) < longest_num_tokens:\n",
        "          one_train_data.append(indices['<PAD>'])\n",
        "\n",
        "        one_train_data.insert(indices['<SOS>'],0)\n",
        "        one_train_data.append(indices['<EOS>'])\n",
        "        data.append(one_train_data)\n",
        "        Y.append(y)\n",
        "    else:\n",
        "      for i in range(num_train, num_train+num_val):\n",
        "        one_val_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "\n",
        "        for token in tokens:\n",
        "          if token not in indices:\n",
        "            one_val_data.append(indices['<UNK>'])\n",
        "          else:\n",
        "            one_val_data.append(indices[token])\n",
        "\n",
        "          if len(one_val_data) == longest_line_tokens:\n",
        "            break\n",
        "\n",
        "        while len(one_val_data) < longest_line_tokens:\n",
        "          one_val_data.append(indices['<PAD>'])\n",
        "\n",
        "        one_val_data.insert(indices['<SOS>'],0)\n",
        "        one_val_data.append(indices['<EOS>'])\n",
        "        data.append(one_val_data)\n",
        "        Y.append(y)\n",
        "    return data, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Kuv3P6ahBQOV"
      },
      "outputs": [],
      "source": [
        "# Loading Training Data & Val Data\n",
        "indices = indexing_tokens()\n",
        "training_data, training_labels = get_data(indices, longest_num_tokens)\n",
        "val_data, val_labels = get_data(indices, longest_num_tokens, mode='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NLYI3st5BQ-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e412f521-7dbb-4f16-c795-f91643e8c22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training: 35000\n",
            "Number of validation: 15000\n",
            "Length of corpus: 122545\n"
          ]
        }
      ],
      "source": [
        "print('Number of training:', len(training_data))\n",
        "print('Number of validation:', len(val_data))\n",
        "print('Length of corpus:', len(indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q5Y91DmNBWQo"
      },
      "outputs": [],
      "source": [
        "# Create tensors of train & val\n",
        "train_tensor = torch.tensor(training_data)\n",
        "train_labels_tensor = torch.tensor(training_labels)\n",
        "val_tensor = torch.tensor(val_data)\n",
        "val_labels_tensor = torch.tensor(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D-aEUFR7CDxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f044c53b-e550-42a0-dfdf-2d2905195def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor: torch.Size([35000, 252])\n",
            "Val Tensor: torch.Size([15000, 252])\n"
          ]
        }
      ],
      "source": [
        "print('Train Tensor:', train_tensor.shape)\n",
        "print('Val Tensor:', val_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5V8feYElCGUp"
      },
      "outputs": [],
      "source": [
        "vocab_size = 122545\n",
        "# embedding_dim = 將每個\"字\" 轉換成 300 個 features\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256 # can be 64, 128, 256 ...\n",
        "sequence_len = 252\n",
        "output_dim = 2 # postive or negative\n",
        "print_every = 400\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0Ute8eQpCar7"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hideen_dim, output_dim):\n",
        "    super().__init__() #讓其可用 forwarding from nn\n",
        "    self.embedding_layer = nn.Embedding(vocab_size, embedding_dim) #字典裡面有 122545個字, 每個字要轉換成300個features\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True)\n",
        "\n",
        "    # 通常输入的第一个维度都是batch_size，比如torch.nn.Linear的输入(batch_size,in_features)，torch.nn.Conv2d的输入（batch_size, C, H, W）。而RNN的输入却是(seq_len, batch_size, input_size)，batch_size位于第二维度！虽然你可以将batch_size和序列长度seq_len对换位置，此时只需要令batch_first=True。\n",
        "    self.fc = nn.Linear(hideen_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    # N(35000) x 252\n",
        "    embedded_data = self.embedding_layer(x) #升維\n",
        "    # N x 300 x 252\n",
        "    output, (h_n, c_n) = self.lstm(embedded_data)\n",
        "    #output : when batch_first=True containing the output features (h_t) from the last layer of the LSTM, for each t.\n",
        "    #h_n : containing the final hidden state for each element in the sequence\n",
        "    #c_n : containing the final cell state for each element in the sequence.\n",
        "    out = output[:,-1,:] #就是 h_n\n",
        "    out = nn.functional.dropout(out) # regularize, 比較不會 overfit\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7Teia3SwDFIy"
      },
      "outputs": [],
      "source": [
        "#initinlize\n",
        "model = MyModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_9wKInieDM0X"
      },
      "outputs": [],
      "source": [
        "mini_trains = DataLoader(train_tensor, batch_size=batch_size)\n",
        "mini_train_labels = DataLoader(training_labels, batch_size=batch_size)\n",
        "\n",
        "mini_vals = DataLoader(val_tensor, batch_size=batch_size)\n",
        "mini_val_labels = DataLoader(val_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qRC2UKTODWf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8246b6-a119-47e8-debe-f4d74eb83650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 252])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "iterator = iter(mini_trains)\n",
        "print(next(iterator).shape)\n",
        "\n",
        "iterator = iter(mini_train_labels)\n",
        "print(next(iterator).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WFc1ieyZDXtY"
      },
      "outputs": [],
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    num_iters = 0\n",
        "    for x, y in zip(mini_trains, mini_train_labels):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      # model(x) = forward\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if num_iters % print_every == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device)\n",
        "      num_iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FiRwQWQTDgzG"
      },
      "outputs": [],
      "source": [
        "# Evaluate Procedure\n",
        "def evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc_count = 0\n",
        "    for x, y in zip(mini_vals, mini_val_labels):\n",
        "      x=x.to(device)\n",
        "      y=y.to(device)\n",
        "      scores=model(x)\n",
        "      predictions=scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      acc_count += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {acc_count/len(val_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qsRrdh9TDkwb"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FaViXpCwDmvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecdcd71-5660-4531-cff5-2c4853865392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.5026\n",
            "Epoch[1] Acc: 0.5065333333333333\n",
            "Epoch[1] Acc: 0.5006\n",
            "Epoch[2] Acc: 0.4988666666666667\n",
            "Epoch[2] Acc: 0.5024666666666666\n",
            "Epoch[2] Acc: 0.5117333333333334\n",
            "Epoch[3] Acc: 0.5081333333333333\n",
            "Epoch[3] Acc: 0.5186666666666667\n",
            "Epoch[3] Acc: 0.5198666666666667\n",
            "Epoch[4] Acc: 0.6680666666666667\n",
            "Epoch[4] Acc: 0.7937333333333333\n",
            "Epoch[4] Acc: 0.8262666666666667\n",
            "Epoch[5] Acc: 0.8481333333333333\n",
            "Epoch[5] Acc: 0.8546\n",
            "Epoch[5] Acc: 0.8668\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "train(5, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ndRyHLHxDpGp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}